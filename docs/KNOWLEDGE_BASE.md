# Knowledge Base Resources

## Coding Interview Resources

### Neetcode-150 and Blind-75
- **Repository**: https://github.com/envico801/Neetcode-150-and-Blind-75
- **Content**: 225 LeetCode problems with Anki flashcards
- **Patterns**: 17 categories (Arrays, Two Pointers, Sliding Window, Stack, Binary Search, Linked Lists, Trees, Tries, Heap, Backtracking, Graphs, 1-D DP, 2-D DP, Greedy, Intervals, Math, Bit Manipulation)

---

## Case Interview Resources

### B-School Casebooks (for future RAG indexing)

| School | Year | Difficulty | Notes | URL |
|--------|------|------------|-------|-----|
| **Kellogg** | All | ⭐⭐⭐ Hard | High-corporate, realistic, challenging. Bad for beginners. | [Search online] |
| **Wharton** | 2017 | ⭐⭐⭐ Hard | Quant-heavy cases | [Link](https://careerinconsulting.com/wp-content/uploads/2019/12/6.-Wharton-Casebook-2017.pdf) |
| **Ross** | 2019 | ⭐ Easy | Beginner-friendly, small business/startup focus | [Link](https://cdn.careers.bloch.umkc.edu/wp-content/uploads/sites/130/2021/11/ProfessionalBusinessSchoolResources-Case-Interviewing.pdf) |
| **Darden** | - | ⭐ Easy | Great for beginners, cover-to-cover reading | [Search online] |
| **Fuqua** | 2019 | ⭐⭐ Medium | - | [Link](https://s3.amazonaws.com/thinkific/file_uploads/163260/attachments/f36/b23/9be/Fuqua_2018.pdf) |
| **Stern** | 2018 | ⭐⭐ Medium | - | [Link](https://careerinconsulting.com/wp-content/uploads/2019/12/9.-Stern-MCA-Casebook-2019.pdf) |
| **HBS** | Unknown | ⭐⭐⭐ Hard | - | [Link](https://www.wallstreetoasis.com/files/hbs_older.pdf) |

**Recommended Path**: Ross/Darden (beginner) → Fuqua/Stern (intermediate) → Kellogg/Wharton/HBS (advanced)

### Consulting Truth Framework
- **Methodology**: Hypothesis-Driven Problem Solving
- **Source**: LinkedIn - Consulting Truth
- **Key Steps**: MECE Structure → Form Hypothesis → Prioritize → Test → Synthesize

---

## Behavioral Interview Resources

### STAR+L Method (Enhanced STAR)
- **S**ituation: Set the scene
- **T**ask: Your specific responsibility
- **A**ction: What YOU did (use "I")
- **R**esult: Quantified impact
- **L**earning: What you learned, how you'd apply it

---

## Future Enhancements

### RAG Pipeline (TODO)
1. Download and parse casebook PDFs
2. Chunk and embed content
3. Store in vector database (Chroma/Pinecone)
4. Query for context-aware responses

### Fine-Tuning (TODO)
1. Extract Q&A pairs from casebooks
2. Format for LoRA/QLoRA fine-tuning
3. Train specialized model for each domain
