# Mac Interview Copilot

A privacy-first macOS interview copilot that provides real-time behavioral and coding assistance using local AI (Ollama) or cloud providers (OpenAI, Anthropic).

## Features

- ğŸ¯ **Behavioral Interview Coaching** - STAR method guidance for behavioral questions
- ğŸ’» **Coding Assistance** - Code review, optimization, and algorithm help
- ğŸ–¥ï¸ **Screen Capture** - OCR to extract context from your screen
- ğŸ”’ **Privacy-First** - Local AI with Ollama, optional cloud providers
- âš¡ **Real-Time Streaming** - Server-Sent Events (SSE) for instant responses
- ğŸ”‘ **MCP Integration** - Model Context Protocol for extensible AI tools

## Quick Start

```bash
# 1. Copy environment config
cp backend/.env.example backend/.env

# 2. Generate JWT secret
./scripts/generate_jwt_secret.sh
# Add the output to your .env

# 3. Start Docker services (includes Ollama)
docker compose -f infra/docker-compose.dev.yml up -d

# 4. Run the Mac client
cd client-mac && swift run MacInterviewCopilotApp
```

**Global Hotkey**: Press `Cmd + Shift + Space` to show/hide the overlay.

## Documentation

- ğŸ“– [**RUNBOOK.md**](./RUNBOOK.md) - Complete setup, usage, and troubleshooting guide
- ğŸ—ï¸ [**Architecture**](./docs/architecture.md) - System design and components
- ğŸ”Œ [**API Reference**](./rest.http) - Test all API endpoints (VS Code REST Client)

## Architecture Overview

```
Mac Client (Swift)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Backend (Node.js/Fastify)
       â”‚                              â”‚
       â”‚  HTTP/SSE                    â”‚
       â”‚                              â–¼
       â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                    â”‚  MCP Service    â”‚
       â”‚                    â”‚  Layer (Tools)  â”‚
       â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                             â”‚
       â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Screen/Audio â”‚            â”‚ Ollama/OpenAI/  â”‚
â”‚   Capture    â”‚            â”‚   Anthropic     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   PostgreSQL    â”‚
                            â”‚     Redis       â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

| Component | Technology |
|-----------|------------|
| **Mac Client** | Swift, SwiftUI, Vision (OCR) |
| **Backend** | Node.js, TypeScript, Fastify |
| **AI Providers** | Ollama (local), OpenAI, Anthropic |
| **MCP Server** | Model Context Protocol for AI tools |
| **Database** | PostgreSQL (persistence), Redis (cache) |
| **Streaming** | Server-Sent Events (SSE) |

## Environment Variables

```bash
# AI Providers (set at least one)
OLLAMA_HOST=http://ollama:11434
OLLAMA_MODEL=llama3.2
OPENAI_API_KEY=sk-...        # Optional
ANTHROPIC_API_KEY=sk-ant-... # Optional

# Security
JWT_SECRET=<generate with scripts/generate_jwt_secret.sh>
```

See [backend/.env.example](./backend/.env.example) for all options.

## Scripts

| Script | Purpose |
|--------|---------|
| `scripts/generate_jwt_secret.sh` | Generate secure JWT secret |
| `scripts/generate-client.sh` | Regenerate OpenAPI Swift client |
| `scripts/validate_ollama.sh` | Validate Ollama connection |

## Privacy

This app prioritizes user privacy:
- **Local AI**: Ollama runs entirely on your machine
- **Session History**: Toggle OFF to disable all data persistence
- **Permissions**: Explicitly requests Screen Recording and Microphone access
- **No Telemetry**: No data sent anywhere except your configured AI provider

## License

MIT
