# Server Configuration
PORT=3000
NODE_ENV=development

# Database & Cache
REDIS_URL=redis://localhost:6379
DATABASE_URL=postgresql://dev:dev@localhost:5432/maccopilot

# JWT Secret (change in production!)
JWT_SECRET=supersecret_dev_key_change_in_prod

# AI Providers - set the ones you want to use
# Leave blank or remove if not using a specific provider

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=

# Anthropic Claude (https://console.anthropic.com/)
ANTHROPIC_API_KEY=

# Ollama - Local AI (runs in Docker or locally)
# For Docker: http://ollama:11434
# For local: http://127.0.0.1:11434
OLLAMA_HOST=http://127.0.0.1:11434

# Ollama Model - which model to use
# Examples: llama3.2, deepseek-coder, codellama, llava (vision), mistral
OLLAMA_MODEL=llama3.2

# Ollama API Key (optional) - for remote Ollama servers requiring auth
# Leave blank for local Docker/localhost Ollama
OLLAMA_API_KEY=

# Google Gemini (Nano Banana) - for image generation (BACKUP)
# Get your key at: https://aistudio.google.com/apikey
GOOGLE_API_KEY=

# ComfyUI - Local Stable Diffusion (DEFAULT, free, unlimited)
# Install ComfyUI: https://github.com/comfyanonymous/ComfyUI
# Run with: python main.py --listen
COMFYUI_HOST=http://127.0.0.1:8188
